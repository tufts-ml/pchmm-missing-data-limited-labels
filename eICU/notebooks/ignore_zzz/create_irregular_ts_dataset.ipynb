{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/cluster/tufts/hugheslab/prath01/projects/time_series_prediction/src/')\n",
    "from split_dataset import split_dataframe_by_keys\n",
    "from feature_transformation import get_fenceposts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.read_csv('/cluster/tufts/hugheslab/datasets/eicu_v2.0/standardized_data/features_per_tstep_first_48_hours_irregular_ts.csv.gz')\n",
    "outcomes_df = pd.read_csv('/cluster/tufts/hugheslab/datasets/eicu_v2.0/standardized_data/outcomes_per_seq_first_48_hours_irregular_ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>mort</th>\n",
       "      <th>los_icu</th>\n",
       "      <th>hospitalid</th>\n",
       "      <th>unittype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128919</td>\n",
       "      <td>141168</td>\n",
       "      <td>1</td>\n",
       "      <td>2.497222</td>\n",
       "      <td>59</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128927</td>\n",
       "      <td>141178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>60</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128927</td>\n",
       "      <td>141179</td>\n",
       "      <td>0</td>\n",
       "      <td>1.418056</td>\n",
       "      <td>60</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128941</td>\n",
       "      <td>141194</td>\n",
       "      <td>0</td>\n",
       "      <td>3.342361</td>\n",
       "      <td>73</td>\n",
       "      <td>CTICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128943</td>\n",
       "      <td>141196</td>\n",
       "      <td>0</td>\n",
       "      <td>1.015972</td>\n",
       "      <td>67</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200854</th>\n",
       "      <td>2743084</td>\n",
       "      <td>3353235</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742361</td>\n",
       "      <td>458</td>\n",
       "      <td>Cardiac ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200855</th>\n",
       "      <td>2743086</td>\n",
       "      <td>3353237</td>\n",
       "      <td>0</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>458</td>\n",
       "      <td>MICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200856</th>\n",
       "      <td>2743099</td>\n",
       "      <td>3353251</td>\n",
       "      <td>0</td>\n",
       "      <td>11.290972</td>\n",
       "      <td>458</td>\n",
       "      <td>Cardiac ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200857</th>\n",
       "      <td>2743102</td>\n",
       "      <td>3353254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299306</td>\n",
       "      <td>459</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200858</th>\n",
       "      <td>2743110</td>\n",
       "      <td>3353263</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>458</td>\n",
       "      <td>MICU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200859 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hadm_id  icustay_id  mort    los_icu  hospitalid      unittype\n",
       "0        128919      141168     1   2.497222          59  Med-Surg ICU\n",
       "1        128927      141178     0   0.005556          60  Med-Surg ICU\n",
       "2        128927      141179     0   1.418056          60  Med-Surg ICU\n",
       "3        128941      141194     0   3.342361          73         CTICU\n",
       "4        128943      141196     0   1.015972          67  Med-Surg ICU\n",
       "...         ...         ...   ...        ...         ...           ...\n",
       "200854  2743084     3353235     0   0.742361         458   Cardiac ICU\n",
       "200855  2743086     3353237     0   0.881250         458          MICU\n",
       "200856  2743099     3353251     0  11.290972         458   Cardiac ICU\n",
       "200857  2743102     3353254     0   0.299306         459  Med-Surg ICU\n",
       "200858  2743110     3353263     0   0.644444         458          MICU\n",
       "\n",
       "[200859 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stays less than 48 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stays : 77832\n",
      "Frac of stays resulting in death : 0.065\n",
      "Frac stays > 3 days : 0.636\n",
      "Frac stays > 7 days : 0.192\n",
      "Frac stays > 11 days : 0.089\n"
     ]
    }
   ],
   "source": [
    "min_stay_hrs = 48\n",
    "keep_inds = outcomes_df['los_icu']>=min_stay_hrs/24.0\n",
    "outcomes_df = outcomes_df.loc[keep_inds, :].copy().reset_index(drop=True)\n",
    "ts_df = ts_df.loc[ts_df['icustay_id'].isin(outcomes_df['icustay_id']), :].reset_index(drop=True)\n",
    "\n",
    "\n",
    "stay_lengths = outcomes_df['los_icu'].values\n",
    "n_stays = len(outcomes_df['icustay_id'].unique())\n",
    "# n_patients = len(outcomes_df['subject_id'].unique())\n",
    "n_deaths = outcomes_df['mort'].sum()\n",
    "\n",
    "print('Total stays : %d'%n_stays)\n",
    "# print('Total patients : %d'%n_patients)\n",
    "print('Frac of stays resulting in death : %.3f'%(n_deaths/n_stays))\n",
    "# print('Frac of patients who die : %.3f'%(n_deaths/n_patients))\n",
    "\n",
    "for min_los in [3, 7, 11]:\n",
    "    inds = stay_lengths>=min_los\n",
    "    frac_above_min_los = len(stay_lengths[inds])/n_stays\n",
    "    print('Frac stays > %d days : %.3f'%(min_los, frac_above_min_los))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature_cols = [\n",
    "        'creatinine',\n",
    "        'potassium',\n",
    "        'sodium', \n",
    "        'platelets x 1000', \n",
    "        'glucose',\n",
    "        'HCO3',\n",
    "        'paO2',\n",
    "        'albumin',\n",
    "        'ALT (SGPT)',\n",
    "        'AST (SGOT)',\n",
    "        'direct bilirubin', \n",
    "        'total bilirubin',\n",
    "        'troponin - T'\n",
    "    ]\n",
    "\n",
    "\n",
    "dem_cols = ['Age', 'is_gender_male', 'is_gender_unknown']\n",
    "id_col = ['stay_id']\n",
    "id_cols = ['subject_id', 'hadm_id', 'stay_id']\n",
    "time_col = ['minutes_from_admission']\n",
    "feature_cols = ts_feature_cols+dem_cols\n",
    "features_df = pd.merge(ts_df, demographics_df, on=id_cols, how='left')\n",
    "\n",
    "features_df['minutes_from_admission']=features_df['minutes_from_admission'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split features into train valid test\n",
    "x_train_df, x_test_df = split_dataframe_by_keys(\n",
    "        features_df, cols_to_group=id_cols, size=0.2, random_state=41)\n",
    "\n",
    "x_train_df, x_valid_df = split_dataframe_by_keys(\n",
    "        x_train_df, cols_to_group=id_cols, size=0.2, random_state=41)\n",
    "\n",
    "# split outcomes into train valid test\n",
    "y_train_df, y_test_df = split_dataframe_by_keys(\n",
    "        outcomes_df, cols_to_group=id_cols, size=0.2, random_state=41)\n",
    "\n",
    "y_train_df, y_valid_df = split_dataframe_by_keys(\n",
    "        y_train_df, cols_to_group=id_cols, size=0.2, random_state=41)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del features_df, ts_df, outcomes_df, demographics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the train/valid/test stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stays : 33506\n",
      "Total patients : 27084\n",
      "Frac of stays resulting in death : 0.081\n",
      "Frac of patients who die : 0.100\n",
      "Frac stays > 3 days in train : 0.467\n",
      "Frac stays > 7 days in train : 0.161\n",
      "Frac stays > 11 days in train : 0.082\n",
      "Total stays : 8377\n",
      "Total patients : 7821\n",
      "Frac of stays resulting in death : 0.080\n",
      "Frac of patients who die : 0.086\n",
      "Frac stays > 3 days in valid : 0.456\n",
      "Frac stays > 7 days in valid : 0.160\n",
      "Frac stays > 11 days in valid : 0.085\n",
      "Total stays : 10471\n",
      "Total patients : 9673\n",
      "Frac of stays resulting in death : 0.084\n",
      "Frac of patients who die : 0.090\n",
      "Frac stays > 3 days in test : 0.472\n",
      "Frac stays > 7 days in test : 0.166\n",
      "Frac stays > 11 days in test : 0.085\n"
     ]
    }
   ],
   "source": [
    "for split, y_df, x_df in [('train', y_train_df, x_train_df),\n",
    "                   ('valid', y_valid_df, x_valid_df),\n",
    "                   ('test', y_test_df, x_test_df)]:\n",
    "\n",
    "    stay_lengths = y_df['length_of_stay_in_hours'].values\n",
    "    n_stays = len(y_df['stay_id'].unique())\n",
    "    n_patients = len(y_df['subject_id'].unique())\n",
    "    n_deaths = y_df['in_icu_mortality'].sum()\n",
    "\n",
    "    print('Total stays : %d'%n_stays)\n",
    "    print('Total patients : %d'%n_patients)\n",
    "    print('Frac of stays resulting in death : %.3f'%(n_deaths/n_stays))\n",
    "    print('Frac of patients who die : %.3f'%(n_deaths/n_patients))\n",
    "    \n",
    "        \n",
    "#     save_dir = '/cluster/tufts/hugheslab/datasets/MIMIC-IV/ordinal_los_prediction/'\n",
    "    for min_los in [3, 7, 11]:\n",
    "        inds = stay_lengths>=min_los*24\n",
    "        frac_above_min_los = len(stay_lengths[inds])/n_stays\n",
    "        print('Frac stays > %d days in %s : %.3f'%(min_los, split, frac_above_min_los))\n",
    "        y_df['los_geq_%s_days'%min_los] = (stay_lengths>=min_los*24)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features (NxTxD), times(NxT) and labels(N) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_ts_matrix(x_df, y_df, outcome_col):\n",
    "    fp = get_fenceposts(x_df, id_cols)\n",
    "    nrows = len(fp)-1\n",
    "    T = 1440\n",
    "    D = len(feature_cols)\n",
    "\n",
    "    X_NTD = np.ones((nrows, T, D), dtype=np.float32)*np.nan\n",
    "    times_NT = np.zeros((nrows, T), dtype=np.float32)\n",
    "    y_N = np.zeros(nrows, dtype=int)\n",
    "    mask_times_NT = np.zeros((nrows, T), dtype=bool)+False\n",
    "    mask_obs_NTD = np.zeros((nrows, T, D), dtype=bool)+False\n",
    "\n",
    "#     outcome_col = 'los_geq_3_days'\n",
    "    for ii in range(nrows):\n",
    "        cur_seq_len = fp[ii+1]-fp[ii]\n",
    "        curr_vals = x_df.iloc[fp[ii]:fp[ii+1]][feature_cols].values\n",
    "        curr_ts = np.squeeze(x_df.iloc[fp[ii]:fp[ii+1]][time_col].values, axis=1)\n",
    "        curr_mask = np.logical_not(np.isnan(curr_vals))\n",
    "\n",
    "        X_NTD[ii, :cur_seq_len, :] = curr_vals\n",
    "        times_NT[ii, :cur_seq_len] = curr_ts\n",
    "        y_N[ii] = y_df.iloc[ii, :][outcome_col]\n",
    "        mask_times_NT[ii, :cur_seq_len] = True\n",
    "        mask_obs_NTD[ii, :cur_seq_len] = curr_mask\n",
    "        \n",
    "    return X_NTD, y_N, times_NT, mask_times_NT, mask_obs_NTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to /cluster/tufts/hugheslab/datasets/MIMIC-IV/ordinal_los_prediction/los_geq_3_days_prediction\n",
      "Done saving train..\n",
      "Done saving valid..\n",
      "Done saving test..\n",
      "Saving data to /cluster/tufts/hugheslab/datasets/MIMIC-IV/ordinal_los_prediction/los_geq_7_days_prediction\n",
      "Done saving train..\n",
      "Done saving valid..\n",
      "Done saving test..\n",
      "Saving data to /cluster/tufts/hugheslab/datasets/MIMIC-IV/ordinal_los_prediction/los_geq_11_days_prediction\n",
      "Done saving train..\n",
      "Done saving valid..\n",
      "Done saving test..\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/cluster/tufts/hugheslab/datasets/MIMIC-IV/ordinal_los_prediction/'\n",
    "suffix = '_irregular_ts'\n",
    "for min_los in [3, 7, 11]:\n",
    "    outcome_col = \"los_geq_%s_days\"%min_los\n",
    "    train_X_NTD, train_y_N, train_times_NT, train_mask_times_NT, train_mask_obs_NTD = convert_csv_to_ts_matrix(x_train_df, \n",
    "                                                                                                               y_train_df,\n",
    "                                                                                                              outcome_col)\n",
    "    \n",
    "    valid_X_NTD, valid_y_N, valid_times_NT, valid_mask_times_NT, valid_mask_obs_NTD = convert_csv_to_ts_matrix(x_valid_df, \n",
    "                                                                                                               y_valid_df,\n",
    "                                                                                                              outcome_col)\n",
    "    test_X_NTD, test_y_N, test_times_NT, test_mask_times_NT, test_mask_obs_NTD = convert_csv_to_ts_matrix(x_test_df, \n",
    "                                                                                                          y_test_df,\n",
    "                                                                                                         outcome_col)\n",
    "    \n",
    "    \n",
    "    \n",
    "    D = train_X_NTD.shape[-1]\n",
    "    \n",
    "    # normalize the data exactly as per mtan\n",
    "    for d in range(D):\n",
    "        mins = np.nanpercentile(train_X_NTD[:, :, d], 1)\n",
    "        maxs = np.nanpercentile(train_X_NTD[:, :, d], 99)\n",
    "        if maxs==0:\n",
    "            maxs=1\n",
    "        train_X_NTD[:, :, d] = (train_X_NTD[:, :, d]-mins)/maxs\n",
    "        valid_X_NTD[:, :, d] = (valid_X_NTD[:, :, d]-mins)/maxs\n",
    "        test_X_NTD[:, :, d] = (test_X_NTD[:, :, d]-mins)/maxs\n",
    "    \n",
    "    curr_save_dir = os.path.join(save_dir, 'los_geq_%s_days_prediction'%min_los)\n",
    "    \n",
    "    \n",
    "    # replace the nan values with 0s\n",
    "    train_X_NTD[np.isnan(train_X_NTD)]=0\n",
    "    valid_X_NTD[np.isnan(valid_X_NTD)]=0\n",
    "    test_X_NTD[np.isnan(test_X_NTD)]=0\n",
    "    \n",
    "    # normalize the observed timepoints between 0 and 1\n",
    "    max_t = np.max(train_times_NT)\n",
    "    train_times_NT = train_times_NT/max_t\n",
    "    valid_times_NT = valid_times_NT/max_t\n",
    "    test_times_NT = test_times_NT/max_t\n",
    "    \n",
    "    print('Saving data to %s'%curr_save_dir)\n",
    "    np.save(os.path.join(curr_save_dir, 'X_train%s.npy'%suffix), \n",
    "            train_X_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_train%s.npy'%suffix), \n",
    "            train_y_N)\n",
    "    np.save(os.path.join(curr_save_dir, 'train_times_NT%s.npy'%suffix), \n",
    "            train_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'train_mask_times_NT%s.npy'%suffix), \n",
    "            train_mask_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'train_mask_obs_NTD%s.npy'%suffix), \n",
    "            train_mask_obs_NTD)\n",
    "\n",
    "    print('Done saving train..')\n",
    "    np.save(os.path.join(curr_save_dir, 'X_valid%s.npy'%suffix), \n",
    "            valid_X_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_valid%s.npy'%suffix), \n",
    "            valid_y_N)\n",
    "    np.save(os.path.join(curr_save_dir, 'valid_times_NT%s.npy'%suffix), \n",
    "            valid_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'valid_mask_times_NT%s.npy'%suffix), \n",
    "            valid_mask_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'valid_mask_obs_NTD%s.npy'%suffix), \n",
    "            valid_mask_obs_NTD)\n",
    "\n",
    "    print('Done saving valid..')\n",
    "    np.save(os.path.join(curr_save_dir, 'X_test%s.npy'%suffix), \n",
    "            test_X_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_test%s.npy'%suffix), \n",
    "            test_y_N)\n",
    "    np.save(os.path.join(curr_save_dir, 'test_times_NT%s.npy'%suffix), \n",
    "            test_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'test_mask_times_NT%s.npy'%suffix), \n",
    "            test_mask_times_NT)\n",
    "    np.save(os.path.join(curr_save_dir, 'test_mask_obs_NTD%s.npy'%suffix), \n",
    "            test_mask_obs_NTD)\n",
    "\n",
    "    print('Done saving test..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1439.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_times_NT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       nan,        nan, 0.39855072, ...,        nan,        nan,\n",
       "              nan], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_NTD[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Heart Rate',\n",
       " 'Respiratory Rate',\n",
       " 'O2 saturation pulseoxymetry',\n",
       " 'Non Invasive Blood Pressure systolic',\n",
       " 'Non Invasive Blood Pressure diastolic',\n",
       " 'Temperature Fahrenheit',\n",
       " 'Height (cm)',\n",
       " 'Respiratory Rate (Total)',\n",
       " 'Potassium (serum)',\n",
       " 'Sodium (serum)',\n",
       " 'Chloride (serum)',\n",
       " 'Hematocrit (serum)',\n",
       " 'Hemoglobin',\n",
       " 'Creatinine (serum)',\n",
       " 'Glucose (serum)',\n",
       " 'Magnesium',\n",
       " 'Phosphorous',\n",
       " 'Platelet Count',\n",
       " 'Glucose (whole blood)',\n",
       " 'Daily Weight',\n",
       " 'Absolute Neutrophil Count',\n",
       " 'Prothrombin time',\n",
       " 'Fibrinogen',\n",
       " 'PH (Arterial)',\n",
       " 'PH (Venous)',\n",
       " 'HCO3 (serum)',\n",
       " 'Arterial O2 pressure',\n",
       " 'Arterial CO2 Pressure',\n",
       " 'Lactic Acid',\n",
       " 'Albumin',\n",
       " 'Calcium non-ionized',\n",
       " 'C Reactive Protein (CRP)',\n",
       " 'ALT',\n",
       " 'AST',\n",
       " 'Direct Bilirubin',\n",
       " 'Total Bilirubin',\n",
       " 'Troponin-T',\n",
       " 'Venous CO2 Pressure',\n",
       " 'Age',\n",
       " 'is_gender_male',\n",
       " 'is_gender_unknown']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'subject_id', 'hadm_id', 'stay_id',\n",
       "       'hours_from_admission', 'timestamp', 'Heart Rate', 'Respiratory Rate',\n",
       "       'O2 saturation pulseoxymetry', 'Non Invasive Blood Pressure systolic',\n",
       "       'Non Invasive Blood Pressure diastolic', 'Temperature Fahrenheit',\n",
       "       'Height (cm)', 'Respiratory Rate (Total)', 'Potassium (serum)',\n",
       "       'Sodium (serum)', 'Chloride (serum)', 'Hematocrit (serum)',\n",
       "       'Hemoglobin', 'Creatinine (serum)', 'Glucose (serum)', 'Magnesium',\n",
       "       'Phosphorous', 'Platelet Count', 'Glucose (whole blood)',\n",
       "       'Daily Weight', 'Absolute Neutrophil Count', 'Prothrombin time',\n",
       "       'Fibrinogen', 'PH (Arterial)', 'PH (Venous)', 'HCO3 (serum)',\n",
       "       'Arterial O2 pressure', 'Arterial CO2 Pressure', 'Lactic Acid',\n",
       "       'Albumin', 'Calcium non-ionized', 'C Reactive Protein (CRP)', 'ALT',\n",
       "       'AST', 'Direct Bilirubin', 'Total Bilirubin', 'Troponin-T',\n",
       "       'Venous CO2 Pressure', 'admission_timestamp_x', 'Age', 'is_gender_male',\n",
       "       'is_gender_unknown', 'admission_timestamp_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Heart Rate',\n",
       " 'Respiratory Rate',\n",
       " 'O2 saturation pulseoxymetry',\n",
       " 'Non Invasive Blood Pressure systolic',\n",
       " 'Non Invasive Blood Pressure diastolic',\n",
       " 'Temperature Fahrenheit',\n",
       " 'Height (cm)',\n",
       " 'Respiratory Rate (Total)',\n",
       " 'Potassium (serum)',\n",
       " 'Sodium (serum)',\n",
       " 'Chloride (serum)',\n",
       " 'Hematocrit (serum)',\n",
       " 'Hemoglobin',\n",
       " 'Creatinine (serum)',\n",
       " 'Glucose (serum)',\n",
       " 'Magnesium',\n",
       " 'Phosphorous',\n",
       " 'Platelet Count',\n",
       " 'Glucose (whole blood)',\n",
       " 'Daily Weight',\n",
       " 'Absolute Neutrophil Count',\n",
       " 'Prothrombin time',\n",
       " 'Fibrinogen',\n",
       " 'PH (Arterial)',\n",
       " 'PH (Venous)',\n",
       " 'HCO3 (serum)',\n",
       " 'Arterial O2 pressure',\n",
       " 'Arterial CO2 Pressure',\n",
       " 'Lactic Acid',\n",
       " 'Albumin',\n",
       " 'Calcium non-ionized',\n",
       " 'C Reactive Protein (CRP)',\n",
       " 'ALT',\n",
       " 'AST',\n",
       " 'Direct Bilirubin',\n",
       " 'Total Bilirubin',\n",
       " 'Troponin-T',\n",
       " 'Venous CO2 Pressure',\n",
       " 'Age',\n",
       " 'is_gender_male',\n",
       " 'is_gender_unknown']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
