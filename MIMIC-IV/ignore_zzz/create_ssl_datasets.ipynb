{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../utils')))\n",
    "sys.path.append(os.path.abspath(os.path.join('../', 'utils', 'GRU-D')))\n",
    "from dataset_loader import TidySequentialDataCSVLoader\n",
    "from utils_preproc import parse_id_cols, parse_output_cols, parse_feature_cols, parse_id_cols, parse_time_cols, load_data_dict_json, get_fenceposts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLF_TRAIN_TEST_SPLIT_PATH = 'data/classifier_train_test_split_dir/'\n",
    "x_train_csv = os.path.join(CLF_TRAIN_TEST_SPLIT_PATH, 'x_trainCustomTimes_10_6_vitals_only.csv.gz')\n",
    "x_valid_csv = os.path.join(CLF_TRAIN_TEST_SPLIT_PATH, 'x_validCustomTimes_10_6_vitals_only.csv.gz')\n",
    "x_test_csv = os.path.join(CLF_TRAIN_TEST_SPLIT_PATH, 'x_testCustomTimes_10_6_vitals_only.csv.gz')\n",
    "\n",
    "\n",
    "y_train_csv = os.path.join(CLF_TRAIN_TEST_SPLIT_PATH, 'y_trainCustomTimes_10_6_vitals_only.csv.gz')\n",
    "y_valid_csv = os.path.join(CLF_TRAIN_TEST_SPLIT_PATH, 'y_validCustomTimes_10_6_vitals_only.csv.gz')\n",
    "y_test_csv = os.path.join(CLF_TRAIN_TEST_SPLIT_PATH, 'y_testCustomTimes_10_6_vitals_only.csv.gz')\n",
    "\n",
    "x_dict_json=os.path.join(CLF_TRAIN_TEST_SPLIT_PATH, 'x_dictCustomTimes_10_6_vitals_only.json')\n",
    "x_data_dict = load_data_dict_json(x_dict_json)\n",
    "\n",
    "x_train_df = pd.read_csv(x_train_csv)\n",
    "x_valid_df = pd.read_csv(x_valid_csv)\n",
    "x_test_df = pd.read_csv(x_test_csv)\n",
    "\n",
    "y_train_df = pd.read_csv(y_train_csv)\n",
    "y_valid_df = pd.read_csv(y_valid_csv)\n",
    "y_test_df = pd.read_csv(y_test_csv)\n",
    "\n",
    "# limit the EHR to first 48 hours\n",
    "max_t = 48\n",
    "x_train_df = x_train_df[x_train_df.stop<=max_t].reset_index(drop=True)\n",
    "y_train_df = y_train_df[y_train_df.stop<=max_t].reset_index(drop=True)\n",
    "\n",
    "x_valid_df = x_valid_df[x_valid_df.stop<=max_t].reset_index(drop=True)\n",
    "y_valid_df = y_valid_df[y_valid_df.stop<=max_t].reset_index(drop=True)\n",
    "\n",
    "x_test_df = x_test_df[x_test_df.stop<=max_t].reset_index(drop=True)\n",
    "y_test_df = y_test_df[y_test_df.stop<=max_t].reset_index(drop=True)\n",
    "\n",
    "y_train_df = y_train_df.drop_duplicates(subset='stay_id', keep='last').reset_index(drop=True)\n",
    "y_valid_df = y_valid_df.drop_duplicates(subset='stay_id', keep='last').reset_index(drop=True)\n",
    "y_test_df = y_test_df.drop_duplicates(subset='stay_id', keep='last').reset_index(drop=True)\n",
    "\n",
    "feature_cols = parse_feature_cols(x_data_dict['schema'])\n",
    "id_cols = parse_id_cols(x_data_dict['schema'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================train===========================\n",
      "Number of slices in train : 42836\n",
      "Frac positive slices in train : 0.0136\n",
      "Number of admissions in train : 42836\n",
      "Frac positive admissions in train : 0.0136\n",
      "===================valid===========================\n",
      "Number of slices in valid : 15443\n",
      "Frac positive slices in valid : 0.0131\n",
      "Number of admissions in valid : 15443\n",
      "Frac positive admissions in valid : 0.0131\n",
      "===================test===========================\n",
      "Number of slices in test : 15802\n",
      "Frac positive slices in test : 0.0116\n",
      "Number of admissions in test : 15802\n",
      "Frac positive admissions in test : 0.0116\n"
     ]
    }
   ],
   "source": [
    "for split, y_df in [('train', y_train_df), \n",
    "                    ('valid', y_valid_df), \n",
    "                    ('test', y_test_df)]:\n",
    "    print('===================%s==========================='%split)\n",
    "    \n",
    "    n_adms_pos_outcome = len(y_df[y_df['in_icu_mortality']==1]['stay_id'].unique())\n",
    "    n_adms_total = len(y_df['stay_id'].unique())\n",
    "    \n",
    "    print('Number of slices in %s : %s'%(split, len(y_df)))\n",
    "    print('Frac positive slices in %s : %.4f'%(split, y_df['in_icu_mortality'].sum()/len(y_df)))\n",
    "    print('Number of admissions in %s : %s'%(split, n_adms_total))\n",
    "    print('Frac positive admissions in %s : %.4f'%(split, n_adms_pos_outcome/n_adms_total))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=x_train_df,\n",
    "    y_csv_path=y_train_df,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"in_icu_mortality\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "valid_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=x_valid_df,\n",
    "    y_csv_path=y_valid_df,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"in_icu_mortality\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "test_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=x_test_df,\n",
    "    y_csv_path=y_test_df,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"in_icu_mortality\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "# num_true_feats = int(F/3)\n",
    "train_x_NTD, y_train = train_vitals.get_batch_data(batch_id=0)\n",
    "valid_x_NTD, y_valid = valid_vitals.get_batch_data(batch_id=0)\n",
    "test_x_NTD, y_test = test_vitals.get_batch_data(batch_id=0)\n",
    "\n",
    "N_tr = len(train_x_NTD)\n",
    "N_va = len(valid_x_NTD)\n",
    "N_te = len(test_x_NTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42836,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "CREATING TRAIN/VALID/TEST SPLITS FOR 1.200 PERCENT OF SEQUENCES LABELLED\n",
      "---------------------------------------------------------------------------\n",
      "Excluded inds train: 3658, 24411, 36568 ... 21793, 12641, 38467\n",
      "Excluded inds valid: 14685, 4004, 13801 ... 14248, 4256, 6648\n",
      "Excluded inds test: 10851, 4531, 10134 ... 6648, 14074, 5532\n",
      "---------------------------------------------------------------------------\n",
      "fraction positive labels in train set with 1.200 percent of sequences labelled : 0.0078\n",
      "fraction positive labels in valid set with 1.200 percent of sequences labelled : 0.0054\n",
      "fraction positive labels in test set with 1.200 percent of sequences labelled : 0.0053\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CREATING TRAIN/VALID/TEST SPLITS FOR 3.700 PERCENT OF SEQUENCES LABELLED\n",
      "---------------------------------------------------------------------------\n",
      "Excluded inds train: 3658, 24411, 36568 ... 12705, 41004, 20243\n",
      "Excluded inds valid: 14685, 4004, 13801 ... 8849, 9201, 5668\n",
      "Excluded inds test: 10851, 4531, 10134 ... 11803, 992, 8849\n",
      "---------------------------------------------------------------------------\n",
      "fraction positive labels in train set with 3.700 percent of sequences labelled : 0.0107\n",
      "fraction positive labels in valid set with 3.700 percent of sequences labelled : 0.0122\n",
      "fraction positive labels in test set with 3.700 percent of sequences labelled : 0.0103\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CREATING TRAIN/VALID/TEST SPLITS FOR 11.100 PERCENT OF SEQUENCES LABELLED\n",
      "---------------------------------------------------------------------------\n",
      "Excluded inds train: 3658, 24411, 36568 ... 6336, 35383, 34955\n",
      "Excluded inds valid: 14685, 4004, 13801 ... 15352, 725, 1279\n",
      "Excluded inds test: 10851, 4531, 10134 ... 405, 10377, 14708\n",
      "---------------------------------------------------------------------------\n",
      "fraction positive labels in train set with 11.100 percent of sequences labelled : 0.0122\n",
      "fraction positive labels in valid set with 11.100 percent of sequences labelled : 0.0105\n",
      "fraction positive labels in test set with 11.100 percent of sequences labelled : 0.0114\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CREATING TRAIN/VALID/TEST SPLITS FOR 33.300 PERCENT OF SEQUENCES LABELLED\n",
      "---------------------------------------------------------------------------\n",
      "Excluded inds train: 3658, 24411, 36568 ... 2042, 2690, 18004\n",
      "Excluded inds valid: 14685, 4004, 13801 ... 2715, 8526, 12908\n",
      "Excluded inds test: 10851, 4531, 10134 ... 8526, 11212, 844\n",
      "---------------------------------------------------------------------------\n",
      "fraction positive labels in train set with 33.300 percent of sequences labelled : 0.0129\n",
      "fraction positive labels in valid set with 33.300 percent of sequences labelled : 0.0130\n",
      "fraction positive labels in test set with 33.300 percent of sequences labelled : 0.0112\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CREATING TRAIN/VALID/TEST SPLITS FOR 100.000 PERCENT OF SEQUENCES LABELLED\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "fraction positive labels in train set with 100.000 percent of sequences labelled : 0.0136\n",
      "fraction positive labels in valid set with 100.000 percent of sequences labelled : 0.0131\n",
      "fraction positive labels in test set with 100.000 percent of sequences labelled : 0.0116\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "state_id = 41\n",
    "data_save_dir = 'data/classifier_train_test_split_dir/'\n",
    "\n",
    "for ii, perc_labelled in enumerate([1.2, 3.7, 11.1, 33.3, 100]):#3.7, 11.1, 33.3, 100\n",
    "    curr_save_dir = os.path.join(data_save_dir, 'percentage_labelled_sequnces=%s'%perc_labelled)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print('CREATING TRAIN/VALID/TEST SPLITS FOR %.3f PERCENT OF SEQUENCES LABELLED'%perc_labelled)\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    y_train_ss = y_train.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_tr = int((1-(perc_labelled)/100)*N_tr)\n",
    "    unlabelled_inds_tr = rnd_state.permutation(N_tr)[:n_unlabelled_tr]\n",
    "    y_train_ss = y_train_ss.astype(np.float32)\n",
    "    y_train_ss[unlabelled_inds_tr] = np.nan  \n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds train: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_tr[0],\n",
    "                                                              unlabelled_inds_tr[1],\n",
    "                                                              unlabelled_inds_tr[2],\n",
    "                                                              unlabelled_inds_tr[-3],\n",
    "                                                              unlabelled_inds_tr[-2],\n",
    "                                                              unlabelled_inds_tr[-1]))\n",
    "    \n",
    "    y_valid_ss = y_valid.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_va = int((1-(perc_labelled)/100)*N_va)\n",
    "    unlabelled_inds_va = rnd_state.permutation(N_va)[:n_unlabelled_va]\n",
    "    y_valid_ss = y_valid_ss.astype(np.float32)\n",
    "    y_valid_ss[unlabelled_inds_va] = np.nan \n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds valid: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_va[0],\n",
    "                                                          unlabelled_inds_va[1],\n",
    "                                                          unlabelled_inds_va[2],\n",
    "                                                          unlabelled_inds_va[-3],\n",
    "                                                          unlabelled_inds_va[-2],\n",
    "                                                          unlabelled_inds_va[-1]))\n",
    "\n",
    "    y_test_ss = y_test.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_te = int((1-(perc_labelled)/100)*N_te)\n",
    "    unlabelled_inds_te = rnd_state.permutation(N_te)[:n_unlabelled_te]\n",
    "    y_test_ss = y_test_ss.astype(np.float32)\n",
    "    y_test_ss[unlabelled_inds_te] = np.nan\n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds test: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_te[0],\n",
    "                                                          unlabelled_inds_te[1],\n",
    "                                                          unlabelled_inds_te[2],\n",
    "                                                          unlabelled_inds_te[-3],\n",
    "                                                          unlabelled_inds_te[-2],\n",
    "                                                          unlabelled_inds_te[-1]))\n",
    "    \n",
    "    print('---------------------------------------------------------------------------')\n",
    "    for split, y in [('train', y_train_ss),\n",
    "                    ('valid', y_valid_ss),\n",
    "                    ('test', y_test_ss)]:\n",
    "        frac_pos_labels = np.nansum(y)/(~np.isnan(y)).sum()\n",
    "        print('fraction positive labels in %s set with %.3f percent of sequences labelled : %.4f'%(split,\n",
    "                                                                                                   perc_labelled,\n",
    "                                                                                                   frac_pos_labels))\n",
    "    print('---------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
