{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sys.path.append('../../utils')\n",
    "from split_dataset import split_dataframe_by_keys\n",
    "from dataset_loader import TidySequentialDataCSVLoader\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the vitals and demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/MIMIC-IV/'\n",
    "suffix = '_first_24_hours'\n",
    "ts_csv = os.path.join(data_dir, 'features_per_tstep%s_los_prediction.csv.gz'%suffix)\n",
    "dem_csv = os.path.join(data_dir, 'demographics%s_los_prediction.csv.gz'%suffix)\n",
    "outcomes_csv = os.path.join(data_dir, 'outcomes_per_seq%s_los_prediction.csv'%suffix)\n",
    "\n",
    "\n",
    "ts_df = pd.read_csv(ts_csv)\n",
    "dem_df = pd.read_csv(dem_csv)\n",
    "outcomes_df = pd.read_csv(outcomes_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stays less than 30 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stays : 52354\n",
      "Total patients : 38939\n",
      "Frac of stays resulting in death : 0.081\n",
      "Frac of patients who die : 0.109\n",
      "Frac stays > 3 days : 0.466\n",
      "Frac stays > 7 days : 0.162\n",
      "Frac stays > 11 days : 0.083\n"
     ]
    }
   ],
   "source": [
    "min_stay_hrs = 30\n",
    "keep_inds = outcomes_df['length_of_stay_in_hours']>=min_stay_hrs\n",
    "outcomes_df = outcomes_df.loc[keep_inds, :].copy().reset_index(drop=True)\n",
    "ts_df = ts_df.loc[ts_df['stay_id'].isin(outcomes_df['stay_id']), :].reset_index(drop=True)\n",
    "dem_df = dem_df.loc[ts_df['stay_id'].isin(outcomes_df['stay_id']), :].reset_index(drop=True)\n",
    "\n",
    "\n",
    "stay_lengths = outcomes_df['length_of_stay_in_hours'].values\n",
    "n_stays = len(outcomes_df['stay_id'].unique())\n",
    "n_patients = len(outcomes_df['subject_id'].unique())\n",
    "n_deaths = outcomes_df['in_icu_mortality'].sum()\n",
    "\n",
    "print('Total stays : %d'%n_stays)\n",
    "print('Total patients : %d'%n_patients)\n",
    "print('Frac of stays resulting in death : %.3f'%(n_deaths/n_stays))\n",
    "print('Frac of patients who die : %.3f'%(n_deaths/n_patients))\n",
    "\n",
    "for min_los in [3, 7, 11]:\n",
    "    inds = stay_lengths>=min_los*24\n",
    "    frac_above_min_los = len(stay_lengths[inds])/n_stays\n",
    "    print('Frac stays > %d days : %.3f'%(min_los, frac_above_min_los))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the range of measurements of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_feature_cols = ['Heart Rate', \n",
    "                    'Respiratory Rate', \n",
    "                    'O2 saturation pulseoxymetry',\n",
    "       'Non Invasive Blood Pressure systolic',\n",
    "       'Non Invasive Blood Pressure diastolic',\n",
    "        'Temperature Fahrenheit',\n",
    "        'Height (cm)',\n",
    "       'Respiratory Rate (Total)', \n",
    "       'Potassium (serum)',\n",
    "       'Sodium (serum)', \n",
    "        'Chloride (serum)', \n",
    "        'Hematocrit (serum)',\n",
    "       'Hemoglobin', \n",
    "        'Creatinine (serum)', \n",
    "        'Glucose (serum)', \n",
    "        'Magnesium', \n",
    "       'Phosphorous', \n",
    "        'Platelet Count', \n",
    "        'Glucose (whole blood)',\n",
    "        'Daily Weight', \n",
    "        'Absolute Neutrophil Count',\n",
    "        'Prothrombin time',\n",
    "        'Fibrinogen',\n",
    "        'PH (Arterial)',\n",
    "        'PH (Venous)',\n",
    "        'HCO3 (serum)',\n",
    "        'Arterial O2 pressure',\n",
    "        'Arterial CO2 Pressure',\n",
    "        'Lactic Acid',\n",
    "        'Albumin',\n",
    "        'Calcium non-ionized',\n",
    "        'C Reactive Protein (CRP)',\n",
    "        'ALT',\n",
    "        'AST',\n",
    "        'Direct Bilirubin', \n",
    "        'Total Bilirubin',\n",
    "        'Troponin-T',\n",
    "        'Venous CO2 Pressure']\n",
    "\n",
    "dem_cols = ['Age', 'is_gender_male', 'is_gender_unknown']\n",
    "id_col = ['stay_id']\n",
    "id_cols = ['subject_id', 'hadm_id', 'stay_id']\n",
    "\n",
    "feature_cols = ts_feature_cols+dem_cols\n",
    "features_df = pd.merge(ts_df, dem_df, on=id_cols, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_col = ['stay_id']\n",
    "time_cols = ['hours_from_admission', 'timestamp']\n",
    "\n",
    "feats_summary_df = pd.DataFrame()\n",
    "for lab in feature_cols:\n",
    "    curr_lab_series = features_df[lab]\n",
    "#     feats_summary_df.loc[lab, 'min'] = curr_lab_series.min()\n",
    "#     feats_summary_df.loc[lab, 'max'] = curr_lab_series.max()\n",
    "    feats_summary_df.loc[lab, '10%'] = np.nanpercentile(curr_lab_series, 10)\n",
    "    feats_summary_df.loc[lab, '90%'] = np.nanpercentile(curr_lab_series, 90)\n",
    "    feats_summary_df.loc[lab, 'median'] = curr_lab_series.median()\n",
    "\n",
    "\n",
    "lab_counts_per_stay_df = features_df.groupby(id_col).count()\n",
    "labs_missing_rate_entire_stay_dict = dict()\n",
    "for lab in feature_cols:\n",
    "    labs_missing_rate_entire_stay_dict[lab] = ((lab_counts_per_stay_df[lab]==0).sum())/lab_counts_per_stay_df.shape[0]\n",
    "labs_missing_rate_entire_stay_series = pd.Series(labs_missing_rate_entire_stay_dict)\n",
    "\n",
    "feats_summary_df.loc[:,'missing_rate'] = labs_missing_rate_entire_stay_series\n",
    "feats_summary_df = feats_summary_df[['10%', 'median', '90%', 'missing_rate']]\n",
    "feats_summary_df.to_csv('ts_feats_summary.csv')\n",
    "feats_summary_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split in train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=41\n",
    "x_train_df, x_test_df = split_dataframe_by_keys(\n",
    "    features_df, cols_to_group=id_cols, size=0.2, random_state=random_state)\n",
    "\n",
    "x_train_df, x_valid_df = split_dataframe_by_keys(\n",
    "        x_train_df, cols_to_group=id_cols, size=0.2, random_state=random_state) \n",
    "\n",
    "\n",
    "y_train_df, y_test_df = split_dataframe_by_keys(\n",
    "    outcomes_df, cols_to_group=id_cols, size=0.2, random_state=random_state)\n",
    "\n",
    "y_train_df, y_valid_df = split_dataframe_by_keys(\n",
    "        y_train_df, cols_to_group=id_cols, size=0.2, random_state=random_state) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the train valid test set stats and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stays : 33506\n",
      "Total patients : 27084\n",
      "Frac of stays resulting in death : 0.081\n",
      "Frac of patients who die : 0.100\n",
      "Frac stays > 3 days in train : 0.467\n",
      "Frac stays > 7 days in train : 0.161\n",
      "Frac stays > 11 days in train : 0.082\n",
      "Total stays : 8377\n",
      "Total patients : 7821\n",
      "Frac of stays resulting in death : 0.080\n",
      "Frac of patients who die : 0.086\n",
      "Frac stays > 3 days in valid : 0.456\n",
      "Frac stays > 7 days in valid : 0.160\n",
      "Frac stays > 11 days in valid : 0.085\n",
      "Total stays : 10471\n",
      "Total patients : 9673\n",
      "Frac of stays resulting in death : 0.084\n",
      "Frac of patients who die : 0.090\n",
      "Frac stays > 3 days in test : 0.472\n",
      "Frac stays > 7 days in test : 0.166\n",
      "Frac stays > 11 days in test : 0.085\n"
     ]
    }
   ],
   "source": [
    "for split, y_df, x_df in [('train', y_train_df, x_train_df),\n",
    "                   ('valid', y_valid_df, x_valid_df),\n",
    "                   ('test', y_test_df, x_test_df)]:\n",
    "\n",
    "    stay_lengths = y_df['length_of_stay_in_hours'].values\n",
    "    n_stays = len(y_df['stay_id'].unique())\n",
    "    n_patients = len(y_df['subject_id'].unique())\n",
    "    n_deaths = y_df['in_icu_mortality'].sum()\n",
    "\n",
    "    print('Total stays : %d'%n_stays)\n",
    "    print('Total patients : %d'%n_patients)\n",
    "    print('Frac of stays resulting in death : %.3f'%(n_deaths/n_stays))\n",
    "    print('Frac of patients who die : %.3f'%(n_deaths/n_patients))\n",
    "    \n",
    "    \n",
    "    save_dir = 'data/MIMIC-IV/mortality_prediction/'\n",
    "    isExist = os.path.exists(save_dir)\n",
    "\n",
    "    if not isExist:\n",
    "        # Create a new directory because it does not exist \n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    \n",
    "    for min_los in [3, 7, 11]:\n",
    "        inds = stay_lengths>=min_los*24\n",
    "        frac_above_min_los = len(stay_lengths[inds])/n_stays\n",
    "        print('Frac stays > %d days in %s : %.3f'%(min_los, split, frac_above_min_los))\n",
    "        y_df['los_geq_%s_days'%min_los] = (stay_lengths>=min_los*24)*1\n",
    "    \n",
    "    x_df.to_csv(os.path.join(save_dir, 'x_%s.csv'%split))   \n",
    "    y_df.to_csv(os.path.join(save_dir, 'y_%s.csv'%split))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the fully supervised train/valid/test splits as numpy arrays for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive label fraction in train : 0.081\n",
      "positive label fraction in valid : 0.080\n",
      "positive label fraction in test : 0.084\n",
      "Saving data to /cluster/tufts/hugheslab/datasets/MIMIC-IV/mortality_prediction/\n",
      "Done saving train..\n",
      "Done saving valid..\n",
      "Done saving test..\n"
     ]
    }
   ],
   "source": [
    "## Convert from dataframe to numpy array of NxTxD\n",
    "train_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=x_train_df,\n",
    "    y_csv_path=y_train_df,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"in_icu_mortality\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "valid_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=x_valid_df,\n",
    "    y_csv_path=y_valid_df,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"in_icu_mortality\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "test_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=x_test_df,\n",
    "    y_csv_path=y_test_df,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"in_icu_mortality\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "train_x_NTD, y_train = train_vitals.get_batch_data(batch_id=0)\n",
    "valid_x_NTD, y_valid = valid_vitals.get_batch_data(batch_id=0)\n",
    "test_x_NTD, y_test = test_vitals.get_batch_data(batch_id=0)\n",
    "\n",
    "N_tr = len(train_x_NTD)\n",
    "N_va = len(valid_x_NTD)\n",
    "N_te = len(test_x_NTD)\n",
    "\n",
    "print('positive label fraction in train : %.3f'%(y_train.sum()/len(y_train)))\n",
    "print('positive label fraction in valid : %.3f'%(y_valid.sum()/len(y_valid)))\n",
    "print('positive label fraction in test : %.3f'%(y_test.sum()/len(y_test)))\n",
    "\n",
    "## save the data\n",
    "\n",
    "# curr_save_dir = os.path.join(save_dir, 'los_geq_%s_days_prediction'%min_los)\n",
    "# # Check whether the specified path exists or not\n",
    "# isExist = os.path.exists(curr_save_dir)\n",
    "\n",
    "# if not isExist:\n",
    "#     # Create a new directory because it does not exist \n",
    "#     os.makedirs(curr_save_dir)\n",
    "\n",
    "# save the data to the respective folder\n",
    "print('Saving data to %s'%save_dir)\n",
    "np.save(os.path.join(save_dir, 'X_train.npy'), train_x_NTD)\n",
    "np.save(os.path.join(save_dir, 'y_train.npy'), y_train)\n",
    "print('Done saving train..')\n",
    "np.save(os.path.join(save_dir, 'X_valid.npy'), valid_x_NTD)\n",
    "np.save(os.path.join(save_dir, 'y_valid.npy'), y_valid)\n",
    "print('Done saving valid..')\n",
    "np.save(os.path.join(save_dir, 'X_test.npy'), test_x_NTD)\n",
    "np.save(os.path.join(save_dir, 'y_test.npy'), y_test)\n",
    "print('Done saving test..')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save binary classification data based on % of labeled sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_id = 41\n",
    "\n",
    "\n",
    "## Convert from dataframe to numpy array of NxTxD\n",
    "train_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=x_train_df,\n",
    "    y_csv_path=y_train_df,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"in_icu_mortality\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "valid_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=x_valid_df,\n",
    "    y_csv_path=y_valid_df,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"in_icu_mortality\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "test_vitals = TidySequentialDataCSVLoader(\n",
    "    x_csv_path=x_test_df,\n",
    "    y_csv_path=y_test_df,\n",
    "    x_col_names=feature_cols,\n",
    "    idx_col_names=id_cols,\n",
    "    y_col_name=\"in_icu_mortality\",\n",
    "    y_label_type='per_sequence'\n",
    ")\n",
    "\n",
    "train_x_NTD, y_train = train_vitals.get_batch_data(batch_id=0)\n",
    "valid_x_NTD, y_valid = valid_vitals.get_batch_data(batch_id=0)\n",
    "test_x_NTD, y_test = test_vitals.get_batch_data(batch_id=0)\n",
    "\n",
    "for ii, perc_labelled in enumerate([1.2, 3.7, 11.1, 33.3, 100]):#3.7, 11.1, 33.3, 100\n",
    "    curr_save_dir = os.path.join(save_dir, 'percentage_labelled_sequences=%s'%perc_labelled)\n",
    "\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print('CREATING TRAIN/VALID/TEST SPLITS FOR %.3f PERCENT OF SEQUENCES LABELLED'%perc_labelled)\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    y_train_ss = y_train.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_tr = int((1-(perc_labelled)/100)*N_tr)\n",
    "    unlabelled_inds_tr = rnd_state.permutation(N_tr)[:n_unlabelled_tr]\n",
    "    y_train_ss = y_train_ss.astype(np.float32)\n",
    "    y_train_ss[unlabelled_inds_tr] = np.nan  \n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds train: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_tr[0],\n",
    "                                                              unlabelled_inds_tr[1],\n",
    "                                                              unlabelled_inds_tr[2],\n",
    "                                                              unlabelled_inds_tr[-3],\n",
    "                                                              unlabelled_inds_tr[-2],\n",
    "                                                              unlabelled_inds_tr[-1]))\n",
    "\n",
    "    y_valid_ss = y_valid.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_va = int((1-(perc_labelled)/100)*N_va)\n",
    "    unlabelled_inds_va = rnd_state.permutation(N_va)[:n_unlabelled_va]\n",
    "    y_valid_ss = y_valid_ss.astype(np.float32)\n",
    "    y_valid_ss[unlabelled_inds_va] = np.nan \n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds valid: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_va[0],\n",
    "                                                          unlabelled_inds_va[1],\n",
    "                                                          unlabelled_inds_va[2],\n",
    "                                                          unlabelled_inds_va[-3],\n",
    "                                                          unlabelled_inds_va[-2],\n",
    "                                                          unlabelled_inds_va[-1]))\n",
    "\n",
    "    y_test_ss = y_test.copy()\n",
    "    rnd_state = np.random.RandomState(state_id)\n",
    "    n_unlabelled_te = int((1-(perc_labelled)/100)*N_te)\n",
    "    unlabelled_inds_te = rnd_state.permutation(N_te)[:n_unlabelled_te]\n",
    "    y_test_ss = y_test_ss.astype(np.float32)\n",
    "    y_test_ss[unlabelled_inds_te] = np.nan\n",
    "    if perc_labelled!=100:\n",
    "        print('Excluded inds test: %d, %d, %d ... %d, %d, %d'%(unlabelled_inds_te[0],\n",
    "                                                          unlabelled_inds_te[1],\n",
    "                                                          unlabelled_inds_te[2],\n",
    "                                                          unlabelled_inds_te[-3],\n",
    "                                                          unlabelled_inds_te[-2],\n",
    "                                                          unlabelled_inds_te[-1]))\n",
    "\n",
    "    # Check whether the specified path exists or not\n",
    "    isExist = os.path.exists(curr_save_dir)\n",
    "\n",
    "    if not isExist:\n",
    "        # Create a new directory because it does not exist \n",
    "        os.makedirs(curr_save_dir)\n",
    "\n",
    "    # save the data to the respective folder\n",
    "    print('Saving data to %s'%curr_save_dir)\n",
    "    np.save(os.path.join(curr_save_dir, 'X_train.npy'), train_x_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_train.npy'), y_train_ss)\n",
    "    print('Done saving train..')\n",
    "    np.save(os.path.join(curr_save_dir, 'X_valid.npy'), valid_x_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_valid.npy'), y_valid_ss)\n",
    "    print('Done saving valid..')\n",
    "    np.save(os.path.join(curr_save_dir, 'X_test.npy'), test_x_NTD)\n",
    "    np.save(os.path.join(curr_save_dir, 'y_test.npy'), y_test_ss)\n",
    "    print('Done saving test..')\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    for split, y in [('train', y_train_ss),\n",
    "                    ('valid', y_valid_ss),\n",
    "                    ('test', y_test_ss)]:\n",
    "        frac_pos_labels = np.nansum(y)/(~np.isnan(y)).sum()\n",
    "        print('fraction positive labels in %s set with %.3f percent of sequences labelled : %.4f'%(split,\n",
    "                                                                                                   perc_labelled,\n",
    "                                                                                                   frac_pos_labels))\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
