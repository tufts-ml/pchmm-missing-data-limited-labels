Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Conda environments: ignored
Job counts:
	count	jobs
	400	train_and_evaluate_classifier
	1	train_and_evaluate_classifier_many_hyperparams
	401

[Thu Oct 27 12:28:55 2022]
rule train_and_evaluate_classifier:
    input: train_pchmm.py, data/train_test_data/x_train_no_imp_observed=100_perc.csv, data/train_test_data/x_valid_no_imp_observed=100_perc.csv, data/train_test_data/x_test_no_imp_observed=100_perc.csv, data/train_test_data/y_train_no_imp_observed=100_perc.csv, data/train_test_data/y_valid_no_imp_observed=100_perc.csv, data/train_test_data/y_test_no_imp_observed=100_perc.csv, data/train_test_data/x_dict_no_imp_observed=100_perc.json, data/train_test_data/y_dict_no_imp_observed=100_perc.json
    output: training_logs/pchmm-missing_handling=no_imp-perc_obs=100-lr=0.01-seed=890-batch_size=-1-lamb=1.csv
    jobid: 329
    wildcards: missing_handling=no_imp, perc_obs=100, lr=0.01, seed=890, batch_size=-1, lamb=1

[Thu Oct 27 12:28:57 2022]
Error in rule train_and_evaluate_classifier:
    jobid: 329
    output: training_logs/pchmm-missing_handling=no_imp-perc_obs=100-lr=0.01-seed=890-batch_size=-1-lamb=1.csv
    shell:
        
        mkdir -p training_logs &&         python -u train_pchmm.py             --outcome_col_name did_overheat_binary_label             --output_dir training_logs             --train_csv_files data/train_test_data/x_train_no_imp_observed=100_perc.csv,data/train_test_data/y_train_no_imp_observed=100_perc.csv             --valid_csv_files data/train_test_data/x_valid_no_imp_observed=100_perc.csv,data/train_test_data/y_valid_no_imp_observed=100_perc.csv             --test_csv_files data/train_test_data/x_test_no_imp_observed=100_perc.csv,data/train_test_data/y_test_no_imp_observed=100_perc.csv             --data_dict_files data/train_test_data/x_dict_no_imp_observed=100_perc.json,data/train_test_data/y_dict_no_imp_observed=100_perc.json             --validation_size 0.15             --lr 0.01             --seed 890             --batch_size -1             --output_filename_prefix pchmm-missing_handling=no_imp-perc_obs=100-lr=0.01-seed=890-batch_size=-1-lamb=1             --lamb 1             --missing_handling no_imp         
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /cluster/tufts/hugheslab/prath01/projects/pchmm_neurips/toydata/.snakemake/log/2022-10-27T122855.418266.snakemake.log
